<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="description" content="Portfolio Website">
    <meta name="keywords" content="HTML, CSS, JavaScript">
    <meta name="author" content="Naadirah Karim">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="normalize.css" />
    <link rel="stylesheet" href="./essay.css"/>
    <link rel="shortcut icon" href="./images/Logo 2.png">
    <script src="https://kit.fontawesome.com/100adece55.js" crossorigin="anonymous"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Dancing+Script:wght@500&display=swap" rel="stylesheet">

    <title>Essay Section</title>
</head>
<body>
    <header>
        <nav id="Navtop">
            <!-- navigation menu webpages + burger button + logo + heading -->
            <input type="checkbox" id="check">
            <label for="check" class="checkbtn">
                <i class="fas fa-bars"></i>
            </label>

            <img src="./images/Logo 2.png" id="logo" />
            <label class="logo">Naadirah Karim.</label>
            

            <ul>
                <li id="home"><a href="index.html">Home</a></li>
                <li id="profile"><a href="./profile.html">My Portfolio</a></li>
                <li id="blog"><a href="./blog.html">Blogs</a></li>
                <li id="design"><a href="./design.html">Design</a></li>
                <li id="essay2"><a href="./essaypost2.html"class= "active">Essay</a></li>
            </ul>
        </nav>   
    </header>
    <h1>Essay</h1> 

    <main>
        <!-- scroll to top button -->
        <a class="gotop" href="#"> <i class="fa-solid fa-arrow-up"></i> </a>

        <!-- return to design overview page -->
        <a class="return" href="essay.html"> <i class="fa-sharp fa-solid fa-arrow-left"></i></a>    
        
        <!-- Essay placeholder -->
        <section id="essay">
                <section class="essayblock">
                    <section class="essaycon">
                        <p class="p-name" ><h2>The Impact of Algorithmic Culture and Artificial Intelligence on The Internet, Society, and Design Justice</h2></p>
                        <article>   
                            <p>
                                The rapid advancements in algorithmic culture and artificial intelligence <dfn>(AI)</dfn> have transformed the landscape of various aspects of our lives, including the internet, society, and the concept of design justice. The pervasive influence of algorithms and data-driven decision-making in different parts of society, such as media, politics, and everyday life, is referred to as algorithmic culture. Artificial intelligence indicates machines or computer systems that exhibit intelligent behaviour, enabling them to perform tasks typically requiring human intelligence, such as learning, reasoning, and problem-solving. 
                                This essay critically examines the impact of algorithmic culture and AI using the <q>Statement on AI Risk</q> released by the Centre for Artificial Intelligence and Society <dfn>(CAIS)</dfn>: <q>Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.</q> <cite><a href=" https://www.safe.ai/statement-on-ai-risk"><em>(Hendrycks, 2023)</em></a></cite> to delve into the implications of algorithmic cultural decision-making, implications for the internet, AI, and society, and biases embedded within AI systems within the context of design justice, which will shed light on the challenges posed by these developments in our increasingly digitized world.
                            </p>                            
                        </article>

                        <article>
                            <p>
                                The <q>Statement on AI Risk" is a statement released by the CAIS</q>, an influential organization devoted to researching and understanding the ethical and social consequences of AI technologies, specifically the potential dangers and risks associated with the development and deployment of artificial intelligence technologies, as defined by CAIS. <q>The signatories include a number of professors from schools like UC Berkeley, MIT, Harvard, and Stanford, as well as executives from tech companies like Microsoft and Google.</q> <cite><a href="https://www.lifestyleasia.com/bk/tech/are-we-worried-about-artificial-intelligence/"><em>(Surbano, 2023)</em></a></cite>. Among the signatories, Sam Altan, the CEO of OpenAI, and Demis Hassabis, the CEO of Google Deepmind, are currently the two main influencers of AI development. <cite><a href="https://www.lifestyleasia.com/bk/tech/are-we-worried-about-artificial-intelligence/"><em>(Surbano, 2023)</em></a></cite>.
                            </p>

                            <p>
                                The statement serves as a call to action and to raise awareness through a critical reflection based on research of the importance of the risks and dangers associated with AI advancements by stating that mitigating the risk of AI-induced human extinction should be a global priority alongside other societal-scale risks. These efforts ensure the safety and responsibility of the development and deployment of AI technologies, intending to safeguard humanity's future. The statement is used to encourage international collaboration between designers, technologists, social scientists, policymakers, and affected communities to develop holistic and contextually appropriate solutions. While promoting responsible data collection, handling, and storage and addressing issues of privacy, consent, and security to protect individuals' inclusivity and social inequalities present among marginalized communities. 
                            </p>

                            <p>
                                The <strong class="p-name">El País article written by Jordi Pérez Colomé </strong>  raises a critical point about the motivations behind the individuals signing doomsday manifestos. It suggests that some individuals who were once strong advocates for AI are now expressing concerns due to the risks associated with its development. <cite><a href="https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html"><em>(COLOMÉ, 2023)</em></a></cite> . Questions are raised about whether the AI industry is adequately addressing the potential dangers and ethical implications of AI technologies. These concerns typically revolve around ethical considerations, potential biases, job displacement, privacy issues, and the potential for AI systems to surpass human intelligence and become uncontrollable.
                                In a Telecoms article written by <strong class="p-name">Scott Bicheno</strong>, the question of what the true motivation behind this statement is: <q>It doesn't seem to have published any details of who funds it, with the only reference we could find on its website being the following in its FAQ section with regards to donations.</q> <cite><a href="https://telecoms.com/521974/ai-leaders-publish-desultory-public-statement-addressing-risk-of-extinction/"><em>(Bicheno, 2023)</em></a></cite>. <q>CAIS is a nonprofit organization. We would not accept funding from stakeholders, which would compromise our mission of reducing AI risk.</q> The donations seem to be used to support CAIS's expenses for research located at an independent lab facility.<cite><a href="https://www.safe.ai/faq"><em>(Hendrycks, 2023)</em></a></cite>. 
                            </p>
                        
                        </article>

                        <article>
                            <p>
                                Algorithmic cultural decision-making, powered by AI, holds great promise in optimizing processes and enhancing efficiency, especially with the role of machine learning in developing social media and search engine algorithms. These algorithms have been criticized for perpetuating bias, fuelling divisions, and contributing to political unrest. <q>Experts warn that as artificial intelligence models become more widespread, these issues will worsen.</q> <cite><a href="https://www.theguardian.com/technology/2023/jun/03/ai-danger-doomsday-chatgpt-robots-fears"><em>(Paul, 2023)</em></a></cite>. <q>AI currently impacts numerous aspects of our lives, including predictive policing and the way search engines curate our news. As newer, more advanced AI models are developed, we can anticipate an even greater presence of AI in our daily lives.</q> <cite><a href="https://www.safe.ai/faq"><em>(Hendrycks, 2023)</em></a></cite>. The <q>Statement on AI Risk</q> underscores the concern that algorithms can perpetuate biases and discriminatory practices, leading to unfair outcomes.
                            </p> 

                            <p>
                                Algorithmic systems have the potential to reinforce power dynamics and perpetuate discriminatory outcomes by amplifying inequalities related to race, gender, and socio-economic status, often due to biases rooted in historical data. This highlights the importance of critically examining and mitigating bias in algorithmic design. Additionally, algorithmic culture can contribute to the exclusion and marginalization of certain groups, such as when algorithmic filtering restricts access to information and resources for marginalized communities, thus perpetuating digital divides. 
                                The shift to online platforms has a disproportionate impact on both marginalized students and less privileged workers. Teleworking, which is primarily accessible to a minority of high-income individuals, is enabled by occupations that do not demand constant physical presence in an office. With the aid of modern technology, remote interaction and collaboration with colleagues and partners can be facilitated. <cite><a href="https://www.internetjustsociety.org/digital-divide-widens"><em>(Maria Tataki, 2020)</em></a></cite>. Recognizing these disparities is crucial for promoting design justice and ensuring equal opportunities for all individuals.
                            </p>
                                                         
                        </article>

                        <article>
                            <p>
                                The incorporation of artificial intelligence (AI) technology into the internet has transformed our online experiences, affecting our ability to access information, communicate, connect, and interact. However, an article in <strong class="p-name">El Pais written by Jordi Pérez Colomé</strong> highlights the concerns expressed by prominent AI advocates in their doomsday manifestos, focusing on the potential negative consequences of unregulated AI development. These consequences include issues such as increased surveillance capitalism, privacy concerns, and the consolidation of power in the hands of dominant entities. <q>Across all metrics, these language models go awry: they're prone to hallucinating, sharing private data, and not respecting copyright laws. [These AI systems] are designed to bolster the power of big tech and increase their ad revenue… theyre marketed deceptively, without proper warning about their limitations.</q> <cite><a href="https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html"><em>(COLOMÉ, 2023)</em></a></cite>. 
                            </p>
                                
                            <p>
                                The <q>Statement on AI Risk</q> underscores the importance of addressing privacy concerns associated with AI systems. The extensive collection and utilization of personal data raises questions about informed consent, data ownership, and control. Additionally, the exploitation of personal data to manipulate individuals' decision-making processes poses risks to democratic processes and creates mistrust among the foundations of civil society.
                            </p>
                                
                            <p>
                                The rapid development of AI has spawned the phenomena of surveillance capitalism, in which personal information is commodified and used for financial benefit. As individuals navigate the online landscape, their every action is tracked, analysed, and leveraged to predict and influence their behaviours.  Furthermore, the articles raise valid concerns about the impact of AI algorithms on social inequalities and the presence of biases within our society. To ensure justice, accountability, and transparency in society, a critical assessment of algorithmic culture and the conceptualization of AI systems is required.
                            </p>
                                        
                        </article>  

                        <article>
                            <p>
                                The level of bias in AI systems depends on the bias present in the data used for their programming. However, societal biases inherent in programming datasets from historical data often permeate AI systems, perpetuating existing inequities that may reflect societal biases and discrimination in their decision-making processes. The <q>Statement on AI Risk</q> draws attention to the potential for AI systems to discriminate against marginalized communities, reinforcing systemic biases and social injustices. This includes biased facial recognition algorithms that disproportionately misidentify individuals of colour and gender, and AI-based hiring systems that replicate discriminatory patterns, reinforcing existing stereotypes. The consequences of biased AI systems are far-reaching.
                            </p>
                                
                            <p>
                                In the <strong class="p-name">El Pais article, Émile Torres</strong> points out that the vision of AI and transhumanism has been shaped by a privileged group of individuals, primarily <q>super-privileged rich white guys</q>. This criticism underscores the significance of diverse representation and power dynamics in the design and development of AI technologies to ensure that the perspectives and needs of marginalized communities are considered.<cite><a href="https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html"><em>(COLOMÉ, 2023)</em></a></cite>. Such biases not only erode trust in AI technology but also deepen existing social divisions and exacerbate inequality.
                            </p>
                                        
                        </article>        

                        <article>
                            <p>
                                Design justice is <q>an approach to design that is led by marginalized communities and that aims explicitly to challenge, rather than reproduce, structural inequalities. It has emerged from a growing community of designers in various fields who work closely with social movements and community-based organizations around the world.</q> <cite><a href="https://designjustice.mitpress.mit.edu/"><em>(Costanza-Chock, 2020)</em></a></cite>. The concept of design justice becomes even more essential regarding the concerns raised in the <strong>El País</strong> article. The article underlines the significance of including diverse perspectives and communities in the design process to ensure that AI aligns with their needs and values. <q>Timnit Gebru, an expert in computer ethics, warns about the biases and dangers of AI models</q> and recognizes the need to hold organizations accountable for the harm caused. This highlights the importance of addressing bias and discrimination in AI systems, which is a key aspect of design justice. <cite><a href="https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html"><em>(COLOMÉ, 2023)</em></a></cite>.
                            </p>
                                
                            <p>
                                Design justice exclaims for addressing the potential harms of AI technologies, including the displacement of workers, as the automation of tasks through AI can lead to job losses and economic disruption. A major concern for the future is that relying excessively on AI systems without appropriate human oversight can diminish human judgment, critical thinking, and ethical reasoning, potentially leading to over-reliance on flawed or biased AI outcomes. The lack of transparency in algorithmic decision-making processes when proprietary algorithms are not subject to public scrutiny can unintentionally reinforce existing biases and inequities, worsening societal divisions. Moreover, the centralization of power in the grasp of corporations that manage these algorithms increases the situation, making transparency and accountability impossible to maintain.
                            </p>
                                
                            <p>
                                <q>Design Justice goes beyond recent calls for design for good, user-centered design, and employment diversity in the technology and design professions; it connects design to larger struggles for collective liberation and ecological survival.</q> <cite><a href="https://designjustice.mitpress.mit.edu/"><em>(Costanza-Chock, 2020)</em></a></cite> and emerges as a necessary response to the challenges posed by algorithmic culture and AI. Entailing and ensuring that the design and operation of technological systems are fair, equitable, and considerate of diverse voices and opinions can decrease the digital divide. By embracing design justice principles, we can strive to address the negative impacts of algorithmic culture and AI on the internet, society, and marginalized communities.
                            </p>

                            <p>
                                Inclusive action and participatory approaches that involve diverse stakeholders in the design and implementation of AI systems are being developed. However, AI-powered algorithms are frequently used to manipulate the public's perceptions, disseminate misinformation, and amplify negative content, endangering democracy, social cohesiveness, ethical quandaries, and human well-being.  <q>Online information can be misleading, so without critical thinking, parts of the digital population can be manipulated.</q> <cite><a href="https://www.internetjustsociety.org/the-need-for-global-internet-connectivity"><em>(Daniolou, 2020)</em></a></cite>. By actively engaging communities affected by AI technologies, researchers can uncover and rectify biases, foster transparency, and promote accountability. Furthermore, design justice highlights the value of multidisciplinary collaboration, acknowledging the necessity for expertise from multiple domains such as ethics, social science research, and the humanities in order to inform AI system development.
                            </p>
                                        
                        </article>        

                        <article>
                            <p>
                                In conclusion, addressing the impact of algorithmic culture and AI on the internet, society, and design justice requires collective efforts. By critically examining the <q>Statement on AI Risk</q> concerning the need for collective action for the risks, biases, and negative consequences associated with these advancements, we can strive to create a future where AI technologies are fair, transparent, and inclusive. These topics—algorithmic cultural decision-making, implications for the internet and society, and biases embedded within AI systems within the context of design justice—are the main reasons the world wide web, society, and the concept of design justice need to be improved. Only by embracing design justice principles and actively involving diverse perspectives can we navigate the complexities of our digitized world and foster a more equitable and just society for all. Thus, making the <q>Statement on AI Risk</q> a reality by preventing humanity's extinction. 
                            </p>                            
                        </article>        

                        <p>
                            <h2>References</h2>
                            <a class="u-url" href="https://telecoms.com/521974/ai-leaders-publish-desultory-public-statement-addressing-risk-of-extinction/">
                            <p class="p-name">Bicheno, S., 2023. Telecoms - AI leaders publish desultory public statement addressing 'risk of extinction'. [Online] Available at: https://telecoms.com/521974/ai-leaders-publish-desultory-public-statement-addressing-risk-of-extinction/ [Accessed 12 June 2023].</p></a>
                            
                            <a class="u-url" href="https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html">
                            <p class="p-name">COLOMÉ, J. P., 2023. EL PAIS - Why are the people who pushed for artificial intelligence now signing so many doomsday manifestos?. [Online] Available at: https://english.elpais.com/science-tech/2023-06-03/why-are-the-people-who-pushed-for-artificial-intelligence-now-signing-so-many-doomsday-manifestos.html [Accessed 13 June 2023].</p></a>
                            
                            <a class="u-url" href="https://designjustice.mitpress.mit.edu/">
                            <p class="p-name">Costanza-Chock, S., 2020. Design Justice. [Online]  Available at: https://designjustice.mitpress.mit.edu/ [Accessed 12 June 2023].</p></a>
                            
                            <a class="u-url" href="https://www.internetjustsociety.org/the-need-for-global-internet-connectivity">
                            <p class="p-name">Daniolou, C., 2020. The Need for Global Internet Connectivity. [Online]  Available at: https://www.internetjustsociety.org/the-need-for-global-internet-connectivity [Accessed 30 May 2023].</p></a>                            
                            
                            <a class="u-url" href=" https://www.safe.ai/statement-on-ai-risk">
                            <p class="p-name">Hendrycks, D., 2023. Center for AI Safety. [Online]  Available at: https://www.safe.ai/statement-on-ai-risk [Accessed 12 June 2023].</p></a>                              
                            
                            <a class="u-url" href="https://www.safe.ai/faq">
                            <p class="p-name">Hendrycks, D., 2023. Center for AI Safety. [Online]  Available at: https://www.safe.ai/faq [Accessed 13 June 2023].</p></a>                             
                            
                            <a class="u-url" href="https://www.internetjustsociety.org/digital-divide-widens">
                            <p class="p-name">Maria Tataki, D. G., 2020. Digital Divide Widens. [Online]  Available at: https://www.internetjustsociety.org/digital-divide-widens [Accessed 30 May 2023].</p></a>                                
                           
                            <a class="u-url" href="https://www.theguardian.com/technology/2023/jun/03/ai-danger-doomsday-chatgpt-robots-fears">
                            <p class="p-name">Paul, K., 2023. the Guardian - Robot takeover? Not quite. Here's what AI doomsday would look like. [Online] [Accessed 13 June 2023].</p></a>                                
                            
                            <a class="u-url" href="https://www.lifestyleasia.com/bk/tech/are-we-worried-about-artificial-intelligence/">
                            <p class="p-name">Surbano, E. E., 2023. Lifestyle Asia - Are we worried about artificial intelligence yet?. [Online] Available at: https://www.lifestyleasia.com/bk/tech/are-we-worried-about-artificial-intelligence/ [Accessed 12 June 2023].</p></a>
                            <p><b>Words: (1950)</b></p>                       
                        </p>
                    </section>
                <a href="./essay.html" class="backbtn"><i class="fa-sharp fa-solid fa-arrow-left"></i></a>    
                </section>   
        </section>        
    </main>

    <script src="./Nav.js"></script>
    <script src="./DOMessay.js"></script>

    <!-- footer -->
    <footer>
        <section class="footerbottom">
            <p>Copyright &copy;2023; Designed by <span class="designer">Naadirah Karim</span> </p>
        </section>
    </footer>
   
</body>
</html>